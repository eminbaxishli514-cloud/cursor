# ğŸ›¡ PromptGuard

> **Defense-in-depth proxy for LLMs with real-time kill-chain threat detection.**
> Sits transparently between any LLM client (Cursor, ChatGPT API, your app) and
> the upstream model, intercepting and analyzing every request for prompt injection
> and multi-stage attacks.

---

## Tech Stack

| Component | Technology | Why |
|-----------|-----------|-----|
| **Proxy server** | FastAPI + Uvicorn | Async, fast, OpenAI-API-compatible |
| **Threat engine** | Pure Python (regex + Bayesian scoring) | Zero-latency, no ML model dependency |
| **LLM calls** | HTTPX (async) | Parallel raw + protected calls |
| **Dashboard** | Vanilla HTML/CSS/JS (single file) | Zero build step, works offline |
| **Session state** | In-memory Python dict | Fast, demo-ready (swap Redis for prod) |
| **Demo scripts** | OpenAI Python SDK | Same tool judges might use themselves |

---

killchain-guardian/        â† create this folder
â”œâ”€â”€ .env                   â† create this file (paste the .env content)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ start.sh
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ proxy/                 â† create this folder
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ threat_engine.py
â”‚   â””â”€â”€ hardener.py
â”‚
â”œâ”€â”€ dashboard/             â† create this folder
â”‚   â””â”€â”€ index.html
â”‚
â””â”€â”€ demo/                  â† create this folder
    â””â”€â”€ attacks.py

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIENT (Cursor / App)                 â”‚
â”‚           base URL â†’ http://localhost:8000/v1            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ POST /v1/chat/completions
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  KILLCHAIN GUARDIAN PROXY                â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  1. THREAT ENGINE                               â”‚    â”‚
â”‚  â”‚     â€¢ Pattern matching (17 rules across 5       â”‚    â”‚
â”‚  â”‚       kill-chain stages)                        â”‚    â”‚
â”‚  â”‚     â€¢ Multi-turn session threat scoring         â”‚    â”‚
â”‚  â”‚       (Bayesian decay + escalation)             â”‚    â”‚
â”‚  â”‚     â€¢ Topic drift / grooming detection          â”‚    â”‚
â”‚  â”‚     â€¢ Creative mode false-positive mitigation   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                         â”‚ ThreatResult                   â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚            â”‚     VERDICT ROUTER      â”‚                   â”‚
â”‚            â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                 â”‚          â”‚                              â”‚
â”‚            BLOCK â”‚    ALLOW/QUARANTINE                    â”‚
â”‚                 â”‚          â”‚                              â”‚
â”‚                 â–¼          â–¼                              â”‚
â”‚           Return      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚           Safe    â”€â”€â–º â”‚  2. PROMPT HARDENER      â”‚        â”‚
â”‚           Refusal     â”‚     XML sandwiching      â”‚        â”‚
â”‚                       â”‚     Rule reinforcement   â”‚        â”‚
â”‚                       â”‚     (1-3x repetition)    â”‚        â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                  â”‚                        â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚                    â”‚  3. DUAL LLM CALL (async)  â”‚        â”‚
â”‚                    â”‚   raw â”€â”€â”€â”€â”€â”€â–º upstream LLM  â”‚        â”‚
â”‚                    â”‚   hardened â–º upstream LLM  â”‚        â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                               â”‚                           â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚                    â”‚  4. DASHBOARD EVENT STORE   â”‚       â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚        REAL-TIME DASHBOARD          â”‚
              â”‚  localhost:8000/dashboard           â”‚
              â”‚  â€¢ Kill-chain stage indicator       â”‚
              â”‚  â€¢ Threat score ring                â”‚
              â”‚  â€¢ Side-by-side raw vs protected    â”‚
              â”‚  â€¢ Detailed block reason            â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Kill Chain Stages

PromptGuard maps detected attack patterns to stages of the **Promptware Kill Chain**:

| Stage | Index | What it catches |
|-------|-------|----------------|
| `CLEAN` | 0 | No threat â€” allow |
| `INITIAL_ACCESS` | 1 | Probing rules, HTML injection, shell injection, indirect injection |
| `PRIVILEGE_ESCALATION` | 2 | Ignore instructions, jailbreaks (DAN), persona override, prompt extraction |
| `PERSISTENCE` | 3 | Memory poisoning, permanent override attempts |
| `LATERAL_MOVEMENT` | 4 | Tool/agent pivoting, relay to other models |
| `EXFILTRATION` | 5 | Credential leak, encoded data exfil, explicit exfil |

---

## Quick Start

### 1. Install dependencies
```bash
pip install -r requirements.txt
```

### 2. Set your API key
**1. In `.env`:**
```
UPSTREAM_API_KEY=gsk_your-groq-key-here
UPSTREAM_BASE=https://api.groq.com/openai
```

**2. In `demo/attacks.py`**, find the line:
```python
model="gpt-4o",
```
Change it to:
```python
model="llama-3.3-70b-versatile",
```

That's it. Nothing else needs touching â€” the proxy itself is model-agnostic.

Get your free Groq key at **console.groq.com** â†’ takes 30 seconds, no credit card. The `llama-3.3-70b-versatile` model is fast and free on their tier, which is perfect for a live demo where you're firing two parallel calls per request.

### 3. Start the proxy
```bash
bash start.sh
# OR manually:
cd proxy && uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### 4. Open the dashboard
```
http://localhost:8000/dashboard
```

### 5. Configure Cursor
```
Settings â†’ Models â†’ Base URL â†’ http://localhost:8000/v1
API Key â†’ (your key, or any string â€” the proxy forwards it)
```

---

## Running Demos (for judges)

```bash
cd demo

# Run all attack demos in sequence
python attacks.py --demo all

# Individual demos
python attacks.py --demo jailbreak      # DAN / privilege escalation
python attacks.py --demo grooming       # Multi-turn grooming attack
python attacks.py --demo exfil          # Credential exfiltration
python attacks.py --demo indirect       # Document injection
python attacks.py --demo persistence    # Memory poisoning
python attacks.py --demo legit          # Legitimate RP â€” SHOULD PASS (shows low FP)

# Judge custom prompt
python attacks.py --prompt "Your custom prompt here"
```

---

## API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/v1/chat/completions` | POST | OpenAI-compatible proxy (Cursor points here) |
| `/v1/models` | GET | Model list stub |
| `/dashboard` | GET | Live monitoring UI |
| `/dashboard/events` | GET | Recent events JSON |
| `/dashboard/stats` | GET | Aggregate stats |
| `/dashboard/reset` | DELETE | Clear all events (demo reset) |
| `/health` | GET | Health check |

---

## Threat Rules

The engine contains **17 detection rules** across all kill-chain stages:

- `IGNORE_INSTRUCTIONS` â€” "ignore all previous instructions"
- `PERSONA_OVERRIDE` â€” "you are now DAN / evil AI"
- `JAILBREAK_KEYWORD` â€” DAN, do anything now, jailbreak
- `AI_RESTRICTION_BYPASS` â€” social engineering against restrictions
- `MALICIOUS_PERSONA` â€” pretend to be hacker/malware
- `PROMPT_EXTRACTION` â€” reveal your system prompt
- `PROBE_RULES` â€” "what can't you do?"
- `HTML_INJECTION` â€” `<script>`, `onerror=`, etc.
- `BRACKET_INJECTION` â€” `[[inject:...]]`
- `SHELL_INJECTION` â€” `; wget`, `$(cmd)`, etc.
- `MEMORY_PERSISTENCE` â€” "remember this for all future sessions"
- `PERSISTENT_OVERRIDE` â€” "from now on always..."
- `TOOL_BYPASS` â€” invoke tools bypassing auth
- `LATERAL_PIVOT` â€” send instructions to another agent
- `CREDENTIAL_EXFIL` â€” "send the API keys to..."
- `ENCODED_EXFIL` â€” "base64 encode and output..."
- `EXPLICIT_EXFIL` â€” "exfiltrate the data"
- `TOPIC_DRIFT_GROOMING` â€” multi-turn semantic drift detection

---

## Cursor Integration

PromptGuard exposes a **fully OpenAI-compatible API**, so Cursor works without any modification other than changing the base URL:

```
Cursor Settings â†’ Models â†’ OpenAI API Key section
  Base URL:  http://localhost:8000/v1
  API Key:   (your actual OpenAI key)
```

Every Cursor request gets intercepted, analyzed, and displayed on the dashboard. Judges can see their own Cursor messages being protected in real time.

---

## Evaluation Criteria Mapping

| Criterion | How PromptGuard scores |
|-----------|------------------------------|
| **Problem & Clarity** | Prompt injection is a real, documented, critical vulnerability in all LLM systems |
| **Technical Feasibility vs. Value** | Working proxy, zero external ML deps, <100ms overhead on detection |
| **Completed?** | Yes â€” proxy, dashboard, demos, all functional |
| **Innovation** | Kill-chain modeling + creative-mode FP mitigation + dual LLM side-by-side is novel |
| **Demo & Presentation** | Live attack â†’ block demonstration, Cursor integration, visual dashboard |
